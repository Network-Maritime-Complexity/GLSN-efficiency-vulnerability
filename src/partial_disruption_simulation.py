import csv
import pandas as pd
import networkx as nx
import efficiency


def foundnetwork(path='../Demo/data/All_routes.csv'):
    df=pd.read_csv(path)
    G = nx.Graph()
    for index, row in df.iterrows():
        ports = set(row['rotation'].split(', '))
        c = row['TEU']/2
        for u in ports:
            for v in ports:
                if (u != v):
                    if ((u, v) in G.edges()):
                        weight = G.get_edge_data(u, v)['weight']
                        G.add_edge(u, v, weight=weight + c,GC=weight + c) #GC and weight are all fake
                    else:
                        G.add_edge(u, v, weight=c,GC=c)
    if('u' in G.nodes()):
        G.remove_node('u')
    print('number_of_nodes: ',G.number_of_nodes())
    print('number_of_edges: ',G.number_of_edges())
    print('nodes: ',G.nodes())
    print('edges: ',G.edges())
    return G

def route_port():
    df=pd.read_csv('../Demo/data/All_routes.csv')
    outer=[]
    for index, row in df.iterrows():
        ports = set(row['rotation'].split(', '))
        for u in ports:
            outer.append([row['route'],u])
    return pd.DataFrame(outer,columns=['route','port'])

def port_criticality(e0,seed,b,n,path1,path2):
    '''
    input parameter:
        seed：random seed
        b: a disruption degree parameter, which indicates the ratio of service routes omitting call at this disrupted port to the total number of service routes originally calling at this port
        path1: the path of file stored for min efficiency between each pair of ports in G0
        path2: the path of file stored for shortest real distance between each pair of ports in G0
    '''
    ports_all=pd.read_csv('../Demo/data/ports.csv')
    portroute = route_port()
    print(portroute)
    for port in ports_all['port'].values:
        df0 = pd.read_csv('../Demo/data/All_routes.csv')
        tmp = portroute[portroute['port'] == str(port)]
        if(len(tmp)!=0):
            routeid = pd.DataFrame(tmp['route'].values, columns=['route'])
            df = pd.merge(routeid, df0, on='route')
            m = round(len(df) * b)
            df = df.sample(m, random_state=seed)
            for index, row in df.iterrows():
                ports = row['rotation'].split(', ')
                strrotation = ''
                for j in range(len(ports)):
                    if (ports[j] == str(port)):
                        strrotation = strrotation + ', u'
                    else:
                        strrotation = strrotation + ', ' + ports[j]
                df0.loc[df0['route'] == row['route'], ['rotation']] = strrotation[2:]
            df0.to_csv('../output/seed=' + str(seed) + ' b=' + str(b) + ' remove port=' + str(port) + '.csv', index=False)
            e0,e,delta=count_e('../output/seed=' + str(seed) + ' b=' + str(b) + ' remove port=' + str(port) + '.csv', str(port),n, path1, path2)
            pd.DataFrame([[port, delta]],columns=['port', 'criticality']).to_csv('../output/port criticality b='+str(b)+'.csv', index=False,header=0,mode='a+')

def country_criticality(e0,seed,b,n,path1,path2):
    '''
        input parameter:
            seed：random seed
            b: a disruption degree parameter, which indicates the ratio of service routes omitting call at this disrupted port to the total number of service routes originally calling at this port
            path1: the path of file stored for min efficiency between each pair of ports in G0
            path2: the path of file stored for shortest real distance between each pair of ports in G0
        '''
    ports_all = pd.read_csv('../Demo/data/ports.csv')
    countries=ports_all.drop_duplicates(['country'])['country'].values
    portroute = route_port()
    print(portroute)
    for country in countries:
        df0 = pd.read_csv('../Demo/data/All_routes.csv')
        print(country)
        ps=ports_all[ports_all['country']==country]
        for port in ps['port'].values:
            tmp = portroute[portroute['port'] == str(port)]
            routeid = pd.DataFrame(tmp['route'].values, columns=['route'])
            df = pd.merge(routeid, df0, on='route')
            m = round(len(df) * b)
            df = df.sample(m, random_state=seed)
            for index, row in df.iterrows():
                ports = row['rotation'].split(', ')
                strrotation = ''
                for j in range(len(ports)):
                    if (ports[j] == str(port)):
                        strrotation = strrotation + ', u'
                    else:
                        strrotation = strrotation + ', ' + ports[j]
                df0.loc[df0['route'] == row['route'], ['rotation']] = strrotation[2:]
        df0.to_csv('../output/seed=' + str(seed) + ' b=' + str(b) + ' remove port=' + str(country) + '.csv', index=False)
        e0, e, delta = count_e('../output/seed=' + str(seed) + ' b=' + str(b) + ' remove port=' + str(country) + '.csv',
                               str(country), n, path1, path2)
        pd.DataFrame([[country, delta]],
                     columns=['country', 'criticality']).to_csv('../output/country criticality b='+str(b)+'.csv', index=False,header=0,mode="a+")

def dismantle_port(e0,seed,b,n,path1,path2):
    '''
        input parameter:
            seed：random seed
            b: a disruption degree parameter, which indicates the ratio of service routes omitting call at this disrupted port to the total number of service routes originally calling at this port
            path1: the path of file stored for min efficiency between each pair of ports in G0
            path2: the path of file stored for shortest real distance between each pair of ports in G0
        '''
    ports_all = pd.read_csv('../output/port criticality b='+str(b)+'.csv').sort_values(by='e')
    portroute = route_port()
    print(portroute)
    df0 = pd.read_csv('../Demo/data/All_routes.csv')
    for port in ports_all['port'].values:
        tmp = portroute[portroute['port'] == str(port)]
        routeid = pd.DataFrame(tmp['route'].values, columns=['route'])
        df = pd.merge(routeid, df0, on='route')
        m = round(len(df) * b)
        df = df.sample(m, random_state=seed)
        for index, row in df.iterrows():
            ports = row['rotation'].split(', ')
            strrotation = ''
            for j in range(len(ports)):
                if (ports[j] == str(port)):
                    strrotation = strrotation + ', u'
                else:
                    strrotation = strrotation + ', ' + ports[j]
            df0.loc[df0['route'] == row['route'], ['rotation']] = strrotation[2:]
    df0.to_csv('../output/seed=' + str(seed) + ' b=' + str(b) + ' remove port=' + str(port) + '.csv', index=False)
    e0, e, delta = count_e('../output/seed=' + str(seed) + ' b=' + str(b) + ' remove port=' + str(port) + '.csv',
                           'dismantle', n, path1, path2)
    pd.DataFrame([[port, delta]],
                     columns=['port', 'delta']).to_csv('../output/dismantle port b='+str(b)+'.csv', index=False,header=0,mode="a+")

def dismantle_country(e0,seed,b,n,path1,path2):
    '''
            input parameter:
                seed：random seed
                b: a disruption degree parameter, which indicates the ratio of service routes omitting call at this disrupted port to the total number of service routes originally calling at this port
                path1: the path of file stored for min efficiency between each pair of ports in G0
                path2: the path of file stored for shortest real distance between each pair of ports in G0
            '''
    ports_all = pd.read_csv('../Demo/data/ports.csv')
    countries = pd.read_csv('../output/country criticality b='+str(b)+'.csv').sort_values(by='e')
    portroute = route_port()
    print(portroute)
    for country in countries:
        df0 = pd.read_csv('../Demo/data/All_routes.csv')
        ps = ports_all[ports_all['country'] == country]
        for port in ps['port'].values:
            tmp = portroute[portroute['port'] == str(port)]
            routeid = pd.DataFrame(tmp['route'].values, columns=['route'])
            df = pd.merge(routeid, df0, on='route')
            m = round(len(df) * b)
            df = df.sample(m, random_state=seed)
            for index, row in df.iterrows():
                ports = row['rotation'].split(', ')
                strrotation = ''
                for j in range(len(ports)):
                    if (ports[j] == str(port)):
                        strrotation = strrotation + ', u'
                    else:
                        strrotation = strrotation + ', ' + ports[j]
                df0.loc[df0['route'] == row['route'], ['rotation']] = strrotation[2:]
    df0.to_csv('../output/seed=' + str(seed) + ' b=' + str(b) + ' remove port=' + str(country) + '.csv', index=False)
    e0, e, delta = count_e('../output/seed=' + str(seed) + ' b=' + str(b) + ' remove port=' + str(country) + '.csv',
                           'dismantle', n, path1, path2)
    pd.DataFrame([[country, delta]],columns=['country', 'delta']).to_csv(
            '../output/dismantle country b='+str(b)+'.csv', index=False,header=0,mode="a+")

def port_vulnerability_to_port_disruption(b):
    df = pd.read_csv('../output/efficiency between each pair of ports under disruption of 77.csv',names=['i','port1', 'port2', 'e'])
    df = df.groupby(by='port1', as_index=False)['e'].sum()
    port = pd.read_csv('../Demo/data/ports')
    df['e'] = df['e'] / len(port)
    for a in port['port'].values:
        if (str(a) != '77'):
            df0 = pd.read_csv('../output/efficiency between each pair of ports under disruption of ' + str(a) + '.csv',names=['i','port1', 'port2', 'e'])
            df0 = df0.groupby(by='port1', as_index=False)['e'].sum()
            df['e'] = df['e'] / len(port)
            dfs = [df, df0]
            df = pd.concat(dfs)
            df = df.groupby(by='port1', as_index=False)['e'].sum()
    df0=pd.read_csv('../output/efficiency between each pair of ports.csv',names=['port1', 'e0', 'port2'])
    df0=df0.groupby(by='port1', as_index=False)['e0'].sum()
    df=df.merge(df0,on=['port1','port2'])
    df['vulnerability']=(df['e0']-df['e'])/df['e0']
    df.to_csv('../output/port vulnerability'+str(b)+'.csv')

def country_vulnerability(b):
    df=pd.read_csv('../output/port vulnerability'+str(b)+'.csv')
    ports=pd.read_csv('../Demo/data/ports.csv')
    df=pd.merge(df,ports,left_on='port1',right_on='port')
    df=df.groupby(by='country')['e','e0'].sum()
    df['vulnerability'] = (df['e0'] - df['e']) / df['e0']
    df.to_csv('../output/country vulnerability'+str(b)+'.csv')

def count_e(path_G,u,n,path1,path2):
    G = foundnetwork(path_G)
    efficiency.efficiency_measurement(G, foundnetwork(), u, n=n, path1=path1, path2=path2)
    df0=pd.read_csv('../output/efficiency between each pair of ports.csv',names=['port1','e0','port2'])
    df0=df0[df0['port1']!=df0['port2']]
    df1=pd.read_csv('../output/efficiency between each pair of ports under disruption of '+u+'.csv',names=['i','port1','port2','e'])
    df=pd.merge(df0,df1,on=['port1','port2'],how='left')
    df['delta']=df['e0']-df['e']
    delta=df[df['delta']>0]['delta'].sum()
    e0=df0['e0'].sum()
    e=df0['e0'].sum()-delta
    delta=(e0-e)/e0
    return e0,e,delta

def main():
    G0=foundnetwork()
    #partial disruption simulation
    #parameters
    seed=1
    bs=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
    path1="../Demo/data/min efficiency between each pair of ports in all realistic routes.csv"
    path2="../Demo/data/distance between each pair of ports.csv"
    n = G0.number_of_nodes()
    e0 = efficiency.efficiency_measurement(G0, G0, n=n, path1=path1, path2=path2)
    print(e0)
    #simulation
    for b in bs:
        port_criticality(e0,seed, b, n,path1, path2)
        country_criticality(e0, seed, b, n,path1, path2)
        dismantle_port(e0,seed, b, n,path1, path2)
        dismantle_country(e0, seed, b, n,path1, path2)
        port_vulnerability_to_port_disruption(b)
        country_vulnerability(b)

